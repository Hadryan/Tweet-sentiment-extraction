{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() #changes word into its original meaning\n",
    "stemmer = PorterStemmer()        #removes suffix\n",
    "def smooth(text):\n",
    "    \n",
    "    #removing urls\n",
    "    text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', text, flags=re.MULTILINE)  # to remove links that start with HTTP/HTTPS in the tweet\n",
    "    text = re.sub(r'[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', text, flags=re.MULTILINE) # to remove other url links\n",
    "    \n",
    "    #removing apostrophes so that contracted words don't lose meaning and saving into remove_apos\n",
    "    remove_apos = [word for word in text if word not in \"'`\"]\n",
    "    remove_apos = ''.join(remove_apos)\n",
    "    print('Apostrophe removed: ',remove_apos)\n",
    "    \n",
    "    #removing punctuatin from remove_apos and saving into text_without_punc\n",
    "    text_without_punc = [word if word not in punctuation else ' ' for word in remove_apos ]\n",
    "    text_without_punc = ''.join(text_without_punc)\n",
    "    print('Without punctuation: ',text_without_punc)\n",
    "    \n",
    "    #removing stop words from text_without_punc and saving into text_without_sw\n",
    "    text_without_sw = [word.lower() for word in text_without_punc.split() if word.lower() not in stopwords.words('english')]\n",
    "    text_without_sw = ' '.join(text_without_sw)\n",
    "    print('Without stop words: ',text_without_sw)\n",
    "    \n",
    "    #removing numbers\n",
    "    text_without_num = [word for word in text_without_sw.split() if not word.isdigit()]\n",
    "    text_without_num = ' '.join(text_without_num)\n",
    "    \n",
    "    #lemmatizing text_without_sw and saving into lemmatized\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text_without_num.split()]\n",
    "    lemmatized = ' '.join(lemmatized)\n",
    "    print('Lemmatized: ',lemmatized)\n",
    "    \n",
    "    #stemming lemmatized and saving into clean_text\n",
    "    clean_text = [stemmer.stem(word) for word in lemmatized.split()]\n",
    "    stemmed = ' '.join(clean_text)\n",
    "    print('Stemmed: ', stemmed)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apostrophe removed:  Kevin believes earth is flat and its making me laugh!I shouldnt laugh 99\n",
      "Without punctuation:  Kevin believes earth is flat and its making me laugh I shouldnt laugh 99\n",
      "Without stop words:  kevin believes earth flat making laugh shouldnt laugh 99\n",
      "Lemmatized:  kevin belief earth flat making laugh shouldnt laugh\n",
      "Stemmed:  kevin belief earth flat make laugh shouldnt laugh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kevin', 'belief', 'earth', 'flat', 'make', 'laugh', 'shouldnt', 'laugh']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Kevin believes earth is flat and it's making me laugh!I shouldn't laugh 99\"\n",
    "smooth(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apostrophe removed:  I absolutely hate this Movie,no more watching more movies!!No I cant even\n",
      "Without punctuation:  I absolutely hate this Movie no more watching more movies  No I cant even\n",
      "Without stop words:  absolutely hate movie watching movies cant even\n",
      "Lemmatized:  absolutely hate movie watching movie cant even\n",
      "Stemmed:  absolut hate movi watch movi cant even\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['absolut', 'hate', 'movi', 'watch', 'movi', 'cant', 'even']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = \"I absolutely hate this Movie,no more watching more movies!!No I can't even\"\n",
    "smooth(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apostrophe removed:  #followfriday thank you so much. Im so behind. Still at about half of what I had. 99\n",
      "Without punctuation:   followfriday thank you so much  Im so behind  Still at about half of what I had  99\n",
      "Without stop words:  followfriday thank much im behind still half 99\n",
      "Lemmatized:  followfriday thank much im behind still half\n",
      "Stemmed:  followfriday thank much im behind still half\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['followfriday', 'thank', 'much', 'im', 'behind', 'still', 'half']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=\"#followfriday thank you so much. I`m so behind. Still at about half of what I had. 99\"\n",
    "smooth(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apostrophe removed:  \n",
      "Without punctuation:  \n",
      "Without stop words:  \n",
      "Lemmatized:  \n",
      "Stemmed:  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = \"https://web.whatsapp.com/\"\n",
    "smooth(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'99'.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
